{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwato\\AppData\\Local\\Temp\\ipykernel_11328\\357239312.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
      "C:\\Users\\zwato\\AppData\\Local\\Temp\\ipykernel_11328\\357239312.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "ZrÃ³bmy szybki preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Nauczmy prosty model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4200      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "history = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "943/943 [==============================] - 3s 2ms/step - loss: 0.4574 - accuracy: 0.7814 - val_loss: 0.3920 - val_accuracy: 0.8096\n",
      "Epoch 2/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3786 - accuracy: 0.8116 - val_loss: 0.3669 - val_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3697 - accuracy: 0.8197 - val_loss: 0.3718 - val_accuracy: 0.8091\n",
      "Epoch 4/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3705 - accuracy: 0.8160 - val_loss: 0.3603 - val_accuracy: 0.8147\n",
      "Epoch 5/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3704 - accuracy: 0.8147 - val_loss: 0.3657 - val_accuracy: 0.8175\n",
      "Epoch 6/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3691 - accuracy: 0.8136 - val_loss: 0.3907 - val_accuracy: 0.7964\n",
      "Epoch 7/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3696 - accuracy: 0.8146 - val_loss: 0.3651 - val_accuracy: 0.8179\n",
      "Epoch 8/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3687 - accuracy: 0.8123 - val_loss: 0.3641 - val_accuracy: 0.8153\n",
      "Epoch 9/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3708 - accuracy: 0.8146 - val_loss: 0.3734 - val_accuracy: 0.8094\n",
      "Epoch 10/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3689 - accuracy: 0.8147 - val_loss: 0.3652 - val_accuracy: 0.8141\n",
      "Epoch 11/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3683 - accuracy: 0.8141 - val_loss: 0.3666 - val_accuracy: 0.8142\n",
      "Epoch 12/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3678 - accuracy: 0.8148 - val_loss: 0.3631 - val_accuracy: 0.8191\n",
      "Epoch 13/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3658 - accuracy: 0.8159 - val_loss: 0.3660 - val_accuracy: 0.8151\n",
      "Epoch 14/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3645 - accuracy: 0.8158 - val_loss: 0.3661 - val_accuracy: 0.8191\n",
      "Epoch 15/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3635 - accuracy: 0.8171 - val_loss: 0.3655 - val_accuracy: 0.8101\n",
      "Epoch 16/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3656 - accuracy: 0.8161 - val_loss: 0.3661 - val_accuracy: 0.8151\n",
      "Epoch 17/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3631 - accuracy: 0.8173 - val_loss: 0.3705 - val_accuracy: 0.8126\n",
      "Epoch 18/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3644 - accuracy: 0.8155 - val_loss: 0.3630 - val_accuracy: 0.8189\n",
      "Epoch 19/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3648 - accuracy: 0.8148 - val_loss: 0.3714 - val_accuracy: 0.8088\n",
      "Epoch 20/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3638 - accuracy: 0.8173 - val_loss: 0.3629 - val_accuracy: 0.8160\n",
      "Epoch 21/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3632 - accuracy: 0.8163 - val_loss: 0.3624 - val_accuracy: 0.8177\n",
      "Epoch 22/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3626 - accuracy: 0.8165 - val_loss: 0.3617 - val_accuracy: 0.8183\n",
      "Epoch 23/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3620 - accuracy: 0.8177 - val_loss: 0.3700 - val_accuracy: 0.8115\n",
      "Epoch 24/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3668 - accuracy: 0.8130 - val_loss: 0.3778 - val_accuracy: 0.8082\n",
      "Epoch 25/100\n",
      "943/943 [==============================] - 3s 4ms/step - loss: 0.3640 - accuracy: 0.8174 - val_loss: 0.3605 - val_accuracy: 0.8198\n",
      "Epoch 26/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3644 - accuracy: 0.8169 - val_loss: 0.3620 - val_accuracy: 0.8195\n",
      "Epoch 27/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3630 - accuracy: 0.8156 - val_loss: 0.3663 - val_accuracy: 0.8184\n",
      "Epoch 28/100\n",
      "943/943 [==============================] - 3s 4ms/step - loss: 0.3656 - accuracy: 0.8148 - val_loss: 0.3651 - val_accuracy: 0.8187\n",
      "Epoch 29/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3648 - accuracy: 0.8151 - val_loss: 0.3625 - val_accuracy: 0.8178\n",
      "Epoch 30/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3633 - accuracy: 0.8174 - val_loss: 0.3621 - val_accuracy: 0.8163\n",
      "Epoch 31/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3627 - accuracy: 0.8186 - val_loss: 0.3619 - val_accuracy: 0.8191\n",
      "Epoch 32/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3612 - accuracy: 0.8169 - val_loss: 0.3623 - val_accuracy: 0.8163\n",
      "Epoch 33/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3618 - accuracy: 0.8168 - val_loss: 0.3628 - val_accuracy: 0.8145\n",
      "Epoch 34/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3622 - accuracy: 0.8159 - val_loss: 0.3644 - val_accuracy: 0.8150\n",
      "Epoch 35/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3634 - accuracy: 0.8170 - val_loss: 0.3666 - val_accuracy: 0.8152\n",
      "Epoch 36/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3623 - accuracy: 0.8172 - val_loss: 0.3690 - val_accuracy: 0.8182\n",
      "Epoch 37/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3661 - accuracy: 0.8156 - val_loss: 0.3718 - val_accuracy: 0.7982\n",
      "Epoch 38/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3644 - accuracy: 0.8154 - val_loss: 0.3738 - val_accuracy: 0.8172\n",
      "Epoch 39/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3644 - accuracy: 0.8152 - val_loss: 0.3666 - val_accuracy: 0.8175\n",
      "Epoch 40/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3634 - accuracy: 0.8142 - val_loss: 0.3730 - val_accuracy: 0.8077\n",
      "Epoch 41/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3626 - accuracy: 0.8179 - val_loss: 0.3641 - val_accuracy: 0.8157\n",
      "Epoch 42/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3608 - accuracy: 0.8176 - val_loss: 0.3622 - val_accuracy: 0.8165\n",
      "Epoch 43/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3610 - accuracy: 0.8158 - val_loss: 0.3660 - val_accuracy: 0.8137\n",
      "Epoch 44/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3632 - accuracy: 0.8145 - val_loss: 0.3700 - val_accuracy: 0.8175\n",
      "Epoch 45/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3632 - accuracy: 0.8170 - val_loss: 0.3650 - val_accuracy: 0.8162\n",
      "Epoch 46/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3631 - accuracy: 0.8154 - val_loss: 0.3672 - val_accuracy: 0.8173\n",
      "Epoch 47/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3620 - accuracy: 0.8150 - val_loss: 0.3634 - val_accuracy: 0.8185\n",
      "Epoch 48/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3620 - accuracy: 0.8164 - val_loss: 0.3628 - val_accuracy: 0.8165\n",
      "Epoch 49/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3624 - accuracy: 0.8181 - val_loss: 0.3689 - val_accuracy: 0.8119\n",
      "Epoch 50/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3610 - accuracy: 0.8164 - val_loss: 0.3642 - val_accuracy: 0.8183\n",
      "Epoch 51/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3607 - accuracy: 0.8170 - val_loss: 0.3738 - val_accuracy: 0.8084\n",
      "Epoch 52/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3598 - accuracy: 0.8168 - val_loss: 0.3751 - val_accuracy: 0.8076\n",
      "Epoch 53/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3593 - accuracy: 0.8175 - val_loss: 0.3649 - val_accuracy: 0.8185\n",
      "Epoch 54/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3597 - accuracy: 0.8179 - val_loss: 0.3793 - val_accuracy: 0.8096\n",
      "Epoch 55/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3593 - accuracy: 0.8180 - val_loss: 0.3630 - val_accuracy: 0.8163\n",
      "Epoch 56/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3584 - accuracy: 0.8186 - val_loss: 0.3680 - val_accuracy: 0.8094\n",
      "Epoch 57/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3601 - accuracy: 0.8182 - val_loss: 0.3650 - val_accuracy: 0.8139\n",
      "Epoch 58/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3592 - accuracy: 0.8181 - val_loss: 0.3664 - val_accuracy: 0.8137\n",
      "Epoch 59/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3586 - accuracy: 0.8190 - val_loss: 0.3660 - val_accuracy: 0.8153\n",
      "Epoch 60/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3582 - accuracy: 0.8189 - val_loss: 0.3646 - val_accuracy: 0.8142\n",
      "Epoch 61/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3569 - accuracy: 0.8180 - val_loss: 0.3668 - val_accuracy: 0.8121\n",
      "Epoch 62/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3771 - accuracy: 0.8153 - val_loss: 0.3645 - val_accuracy: 0.8174\n",
      "Epoch 63/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3599 - accuracy: 0.8163 - val_loss: 0.3636 - val_accuracy: 0.8177\n",
      "Epoch 64/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3600 - accuracy: 0.8174 - val_loss: 0.3680 - val_accuracy: 0.8125\n",
      "Epoch 65/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3590 - accuracy: 0.8185 - val_loss: 0.3710 - val_accuracy: 0.8088\n",
      "Epoch 66/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3578 - accuracy: 0.8187 - val_loss: 0.3636 - val_accuracy: 0.8167\n",
      "Epoch 67/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3593 - accuracy: 0.8175 - val_loss: 0.3639 - val_accuracy: 0.8184\n",
      "Epoch 68/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3635 - accuracy: 0.8176 - val_loss: 0.3800 - val_accuracy: 0.7904\n",
      "Epoch 69/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3617 - accuracy: 0.8156 - val_loss: 0.3647 - val_accuracy: 0.8178\n",
      "Epoch 70/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3574 - accuracy: 0.8189 - val_loss: 0.3635 - val_accuracy: 0.8169\n",
      "Epoch 71/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3617 - accuracy: 0.8169 - val_loss: 0.3685 - val_accuracy: 0.8183\n",
      "Epoch 72/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3595 - accuracy: 0.8193 - val_loss: 0.3664 - val_accuracy: 0.8150\n",
      "Epoch 73/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3600 - accuracy: 0.8176 - val_loss: 0.3635 - val_accuracy: 0.8175\n",
      "Epoch 74/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3608 - accuracy: 0.8164 - val_loss: 0.3646 - val_accuracy: 0.8161\n",
      "Epoch 75/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3620 - accuracy: 0.8164 - val_loss: 0.3657 - val_accuracy: 0.8143\n",
      "Epoch 76/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3577 - accuracy: 0.8182 - val_loss: 0.3631 - val_accuracy: 0.8170\n",
      "Epoch 77/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3620 - accuracy: 0.8166 - val_loss: 0.3659 - val_accuracy: 0.8183\n",
      "Epoch 78/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3585 - accuracy: 0.8182 - val_loss: 0.3917 - val_accuracy: 0.7809\n",
      "Epoch 79/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3562 - accuracy: 0.8202 - val_loss: 0.3668 - val_accuracy: 0.8139\n",
      "Epoch 80/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3584 - accuracy: 0.8190 - val_loss: 0.3762 - val_accuracy: 0.8088\n",
      "Epoch 81/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3619 - accuracy: 0.8141 - val_loss: 0.3673 - val_accuracy: 0.8175\n",
      "Epoch 82/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3593 - accuracy: 0.8175 - val_loss: 0.3688 - val_accuracy: 0.8141\n",
      "Epoch 83/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3573 - accuracy: 0.8207 - val_loss: 0.3707 - val_accuracy: 0.8109\n",
      "Epoch 84/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3560 - accuracy: 0.8195 - val_loss: 0.3630 - val_accuracy: 0.8161\n",
      "Epoch 85/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3575 - accuracy: 0.8195 - val_loss: 0.3634 - val_accuracy: 0.8176\n",
      "Epoch 86/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3567 - accuracy: 0.8193 - val_loss: 0.3631 - val_accuracy: 0.8177\n",
      "Epoch 87/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3549 - accuracy: 0.8199 - val_loss: 0.3694 - val_accuracy: 0.8166\n",
      "Epoch 88/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3544 - accuracy: 0.8218 - val_loss: 0.3589 - val_accuracy: 0.8216\n",
      "Epoch 89/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3605 - accuracy: 0.8168 - val_loss: 0.3718 - val_accuracy: 0.8111\n",
      "Epoch 90/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3599 - accuracy: 0.8184 - val_loss: 0.3654 - val_accuracy: 0.8181\n",
      "Epoch 91/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3565 - accuracy: 0.8199 - val_loss: 0.3693 - val_accuracy: 0.8195\n",
      "Epoch 92/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3570 - accuracy: 0.8191 - val_loss: 0.3641 - val_accuracy: 0.8191\n",
      "Epoch 93/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3551 - accuracy: 0.8213 - val_loss: 0.3615 - val_accuracy: 0.8197\n",
      "Epoch 94/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3581 - accuracy: 0.8178 - val_loss: 0.3740 - val_accuracy: 0.8097\n",
      "Epoch 95/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3567 - accuracy: 0.8194 - val_loss: 0.3660 - val_accuracy: 0.7959\n",
      "Epoch 96/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3561 - accuracy: 0.8206 - val_loss: 0.3931 - val_accuracy: 0.7945\n",
      "Epoch 97/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3635 - accuracy: 0.8146 - val_loss: 0.3784 - val_accuracy: 0.8129\n",
      "Epoch 98/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3584 - accuracy: 0.8200 - val_loss: 0.3618 - val_accuracy: 0.8206\n",
      "Epoch 99/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3556 - accuracy: 0.8194 - val_loss: 0.3642 - val_accuracy: 0.8173\n",
      "Epoch 100/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3559 - accuracy: 0.8201 - val_loss: 0.3644 - val_accuracy: 0.8178\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n",
    "history = model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 1s 1ms/step - loss: 0.3644 - accuracy: 0.8178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3644145131111145, 0.81779545545578]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.round(model.predict(X_test))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177954847277557"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import  metrics\n",
    "metrics.accuracy_score(y_true= y_test, y_pred= np.round(model.predict(X_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "PorÃ³wnaj powyÅ¼szy wynik z naukÄ na danych znormalizowanych z frÃ³Å¼nymi funkcjami aktywacji:\n",
    "* sigmoid\n",
    "* tanh\n",
    "* relu\n",
    "* elu\n",
    "* LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_norm, y_train_norm = StandardScaler().fit_transform(X_train), y_train\n",
    "\n",
    "sigmoid_history = History()\n",
    "sigmod_model = Sequential([\n",
    "    Dense(100, activation='sigmoid', input_shape=(X_train_norm.shape[1],)),\n",
    "    Dense(50, activation='sigmoid'),\n",
    "    Dense(10, activation='sigmoid'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "tanh_history = History()\n",
    "tanh_model = Sequential([\n",
    "    Dense(100, activation='tanh', input_shape=(X_train_norm.shape[1],)),\n",
    "    Dense(50, activation='tanh'),\n",
    "    Dense(10, activation='tanh'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "relu_history = History()\n",
    "relu_model = Sequential([\n",
    "    Dense(100, activation='relu', input_shape=(X_train_norm.shape[1],)),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "elu_history = History()\n",
    "elu_model = Sequential([\n",
    "    Dense(100, activation='elu', input_shape=(X_train_norm.shape[1],)),\n",
    "    Dense(50, activation='elu'),\n",
    "    Dense(10, activation='elu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "leaky_relu_history = History()\n",
    "leaky_relu_model = Sequential([\n",
    "    Dense(100, activation='leaky_relu', input_shape=(X_train_norm.shape[1],)),\n",
    "    Dense(50, activation='leaky_relu'),\n",
    "    Dense(10, activation='leaky_relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "943/943 [==============================] - 3s 2ms/step - loss: 0.3160 - accuracy: 0.8507 - val_loss: 1.0503 - val_accuracy: 0.2681\n",
      "Epoch 2/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3149 - accuracy: 0.8518 - val_loss: 0.9542 - val_accuracy: 0.2898\n",
      "Epoch 3/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3141 - accuracy: 0.8548 - val_loss: 0.8382 - val_accuracy: 0.3635\n",
      "Epoch 4/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3126 - accuracy: 0.8521 - val_loss: 0.8768 - val_accuracy: 0.3610\n",
      "Epoch 5/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3112 - accuracy: 0.8543 - val_loss: 0.8854 - val_accuracy: 0.3744\n",
      "Epoch 6/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3104 - accuracy: 0.8544 - val_loss: 0.7520 - val_accuracy: 0.6039\n",
      "Epoch 7/10\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3092 - accuracy: 0.8557 - val_loss: 0.7555 - val_accuracy: 0.5682\n",
      "Epoch 8/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3081 - accuracy: 0.8556 - val_loss: 0.8069 - val_accuracy: 0.4639\n",
      "Epoch 9/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3074 - accuracy: 0.8559 - val_loss: 0.7364 - val_accuracy: 0.6464\n",
      "Epoch 10/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3062 - accuracy: 0.8571 - val_loss: 0.7142 - val_accuracy: 0.7426\n",
      "471/471 [==============================] - 1s 1ms/step - loss: 0.7142 - accuracy: 0.7426\n",
      "Epoch 1/10\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3475 - accuracy: 0.8371 - val_loss: 1.5436 - val_accuracy: 0.2463\n",
      "Epoch 2/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3224 - accuracy: 0.8485 - val_loss: 1.0696 - val_accuracy: 0.3415\n",
      "Epoch 3/10\n",
      "943/943 [==============================] - 3s 4ms/step - loss: 0.3152 - accuracy: 0.8520 - val_loss: 0.7105 - val_accuracy: 0.6288\n",
      "Epoch 4/10\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3109 - accuracy: 0.8557 - val_loss: 0.7427 - val_accuracy: 0.5774\n",
      "Epoch 5/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3073 - accuracy: 0.8567 - val_loss: 0.7339 - val_accuracy: 0.6285\n",
      "Epoch 6/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3039 - accuracy: 0.8573 - val_loss: 0.7905 - val_accuracy: 0.4940\n",
      "Epoch 7/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3008 - accuracy: 0.8595 - val_loss: 1.0620 - val_accuracy: 0.3871\n",
      "Epoch 8/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2984 - accuracy: 0.8614 - val_loss: 1.2660 - val_accuracy: 0.3479\n",
      "Epoch 9/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2959 - accuracy: 0.8616 - val_loss: 0.7410 - val_accuracy: 0.6742\n",
      "Epoch 10/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2937 - accuracy: 0.8631 - val_loss: 0.7772 - val_accuracy: 0.5552\n",
      "471/471 [==============================] - 1s 1ms/step - loss: 0.7772 - accuracy: 0.5552\n",
      "Epoch 1/10\n",
      "943/943 [==============================] - 3s 2ms/step - loss: 0.3424 - accuracy: 0.8397 - val_loss: 166.0261 - val_accuracy: 0.2657\n",
      "Epoch 2/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3176 - accuracy: 0.8532 - val_loss: 203.4316 - val_accuracy: 0.3871\n",
      "Epoch 3/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3122 - accuracy: 0.8538 - val_loss: 197.5335 - val_accuracy: 0.5932\n",
      "Epoch 4/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3088 - accuracy: 0.8553 - val_loss: 220.8641 - val_accuracy: 0.7317\n",
      "Epoch 5/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3076 - accuracy: 0.8564 - val_loss: 244.1293 - val_accuracy: 0.7635\n",
      "Epoch 6/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3042 - accuracy: 0.8588 - val_loss: 288.1074 - val_accuracy: 0.7750\n",
      "Epoch 7/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3024 - accuracy: 0.8593 - val_loss: 290.0643 - val_accuracy: 0.7751\n",
      "Epoch 8/10\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2999 - accuracy: 0.8594 - val_loss: 295.4546 - val_accuracy: 0.7754\n",
      "Epoch 9/10\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2985 - accuracy: 0.8615 - val_loss: 330.2586 - val_accuracy: 0.7754\n",
      "Epoch 10/10\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2961 - accuracy: 0.8623 - val_loss: 337.1455 - val_accuracy: 0.7754\n",
      "471/471 [==============================] - 1s 2ms/step - loss: 337.1455 - accuracy: 0.7754\n",
      "Epoch 1/10\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.3403 - accuracy: 0.8397 - val_loss: 37.7477 - val_accuracy: 0.7748\n",
      "Epoch 2/10\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3203 - accuracy: 0.8501 - val_loss: 51.1978 - val_accuracy: 0.7748\n",
      "Epoch 3/10\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.3148 - accuracy: 0.8523 - val_loss: 58.0328 - val_accuracy: 0.7754\n",
      "Epoch 4/10\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3121 - accuracy: 0.8559 - val_loss: 87.8019 - val_accuracy: 0.7754\n",
      "Epoch 5/10\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3090 - accuracy: 0.8549 - val_loss: 109.3578 - val_accuracy: 0.7754\n",
      "Epoch 6/10\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3077 - accuracy: 0.8576 - val_loss: 68.9904 - val_accuracy: 0.7754\n",
      "Epoch 7/10\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3049 - accuracy: 0.8589 - val_loss: 70.4002 - val_accuracy: 0.7754\n",
      "Epoch 8/10\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3023 - accuracy: 0.8592 - val_loss: 55.0794 - val_accuracy: 0.7754\n",
      "Epoch 9/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3012 - accuracy: 0.8602 - val_loss: 52.5009 - val_accuracy: 0.7754\n",
      "Epoch 10/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2998 - accuracy: 0.8594 - val_loss: 9.3061 - val_accuracy: 0.7754\n",
      "471/471 [==============================] - 1s 1ms/step - loss: 9.3061 - accuracy: 0.7754\n",
      "Epoch 1/10\n",
      "943/943 [==============================] - 3s 2ms/step - loss: 0.3400 - accuracy: 0.8405 - val_loss: 185.0300 - val_accuracy: 0.3086\n",
      "Epoch 2/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3188 - accuracy: 0.8519 - val_loss: 207.8197 - val_accuracy: 0.4018\n",
      "Epoch 3/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3138 - accuracy: 0.8541 - val_loss: 213.7980 - val_accuracy: 0.7754\n",
      "Epoch 4/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3108 - accuracy: 0.8574 - val_loss: 250.0107 - val_accuracy: 0.7566\n",
      "Epoch 5/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3090 - accuracy: 0.8571 - val_loss: 222.3999 - val_accuracy: 0.7754\n",
      "Epoch 6/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3076 - accuracy: 0.8566 - val_loss: 231.5454 - val_accuracy: 0.7754\n",
      "Epoch 7/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3052 - accuracy: 0.8587 - val_loss: 238.6880 - val_accuracy: 0.7754\n",
      "Epoch 8/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3041 - accuracy: 0.8586 - val_loss: 240.9186 - val_accuracy: 0.7754\n",
      "Epoch 9/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3026 - accuracy: 0.8595 - val_loss: 197.1757 - val_accuracy: 0.7754\n",
      "Epoch 10/10\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3003 - accuracy: 0.8602 - val_loss: 350.4929 - val_accuracy: 0.7754\n",
      "471/471 [==============================] - 1s 1ms/step - loss: 350.4929 - accuracy: 0.7754\n"
     ]
    }
   ],
   "source": [
    "for model in [sigmod_model, tanh_model, relu_model, elu_model, leaky_relu_model]:\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    model.fit(X_train_norm, y_train_norm, validation_data=(X_test, y_test), batch_size=32, epochs=10, callbacks=[history])\n",
    "    model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad. \n",
    "StwÃ³rz wykres porÃ³wnujÄcy metody. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11328\\2095094045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhis\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msigmoid_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtanh_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelu_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melu_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleaky_relu_history\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ax\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"left_ax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# no non-numeric frames or series allowed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no numeric data to plot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_ndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "for his in [sigmoid_history, tanh_history, relu_history, elu_history, leaky_relu_history]:\n",
    "    pd.DataFrame(his.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e284ee3255a07ad8bf76694974743c4c81cb57e7c969474d752d949b11d721e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
